# ğŸ—„ï¸ pdp-dw-powerbi
[![Projeto Badge](https://img.shields.io/badge/-pdp--hospedagem-2B5482?style=flat-square&logo=github&logoColor=fff)](https://github.com/rafa-trindade/pdp-hospedagem)

Este projeto realiza a **implementaÃ§Ã£o, modelagem e consumo de um Data Warehouse** utilizando **Airflow**, **DBT** e **Power BI**, integrando dados transacionais do projeto [pdp-hospedagem](https://github.com/rafa-trindade/pdp-hospedagem).

O projeto contempla:  
- **ConteinerizaÃ§Ã£o da aplicaÃ§Ã£o** com **Docker**, garantindo isolamento, portabilidade e facilidade de execuÃ§Ã£o dos serviÃ§os (Airflow, PostgreSQL, DBT);  
- **OrquestraÃ§Ã£o de pipelines** utilizando o **Apache Airflow**;  
- **TransformaÃ§Ã£o, documentaÃ§Ã£o e modelagem** utilizando o **DBT**:
- **Consumo** dos modelos com o **Power BI** para criaÃ§Ã£o de dashboards e relaÃ³rios.  

---

## ğŸ“ Progresso do Projeto:

- âœ… CriaÃ§Ã£o das dimensÃµes `dim_date` e `dim_time` via Python que serÃ£o utilizadas como **seeds** no DBT.  
- âœ… IngestÃ£o de dados transacionais fictÃ­cios no banco de dados **SQL Server** do projeto [**pdp-hospedagem**](https://github.com/rafa-trindade/pdp-hospedagem) utilizando [**datafaker-rafatrindade**](https://github.com/rafa-trindade/datafaker-rafatrindade).  
- âœ… **ConteinerizaÃ§Ã£o** do projeto utilizando **Docker**, com configuraÃ§Ã£o de:
  - **Dockerfile** para instalar dependÃªncias necessÃ¡rias e preparar o container do Airflow.
  - **docker-compose.yml** para orquestrar o Airflow e os containers de banco de dados (**SQL Server** e **PostgreSQL**).
- âœ… ImplementaÃ§Ã£o da **extraÃ§Ã£o (Extract)** dos dados transacionais via pipeline do **Airflow**, com arquivos extraÃ­dos salvos na pasta `data/extracted`.  

---

## ğŸš§ PrÃ³ximos Passos:

- **Carga (Load)** dos dados extraÃ­dos do SQL Server para o PostgreSQL via pipeline orquestrada no Airflow.  
- **TransformaÃ§Ãµes (Transform)** dos dados no DBT, estruturando as camadas **staging**, **core**.  
- Modelagem das **tabelas fato** e **dimensÃµes analÃ­ticas** utilizando o DBT na camada camada **data mart**.  
- Consumo dos modelos com o **Power BI** para criaÃ§Ã£o de dashboards e relaÃ³rios.  

---

### ğŸ” Resumo da Arquitetura ELT e Dataviz:

1. **Extract:** ExtraÃ§Ã£o dos dados transacionais do SQL Server via Airflow. *(Etapa concluÃ­da âœ…)*  
2. **Load:** Carga dos dados brutos no Data Warehouse (PostgreSQL). *(PrÃ³xima etapa ğŸš§)*  
3. **Transform:** TransformaÃ§Ãµes e modelagem realizadas pelo DBT diretamente no Data Warehouse. *(Etapa futura ğŸ”œ)* 
4. **Dataviz:** Consumo e anÃ¡lise dos dados no **Power BI**, com desenvolvimento de dashboards e relatÃ³rios. *(Etapa futura ğŸ”œ)*  

---

## ğŸ“¦ Bibliotecas Utilizadas:

**Ambiente:** Python 3.11  

| Pacote            | VersÃ£o  | ObservaÃ§Ã£o |
|-------------------|---------|------------|
| **pandas**         | 2.3.3    | ManipulaÃ§Ã£o e transformaÃ§Ã£o de dados |
| **requests**       | 2.32.3   | RequisiÃ§Ãµes HTTP e integraÃ§Ã£o de APIs |
| **python-dotenv**  | 1.0.1    | Carregamento de variÃ¡veis de ambiente do arquivo `.env` |
| **dbt-core**       | 1.10.13  | TransformaÃ§Ãµes e modelagem no Data Warehouse |
| **dbt-postgres**   | 1.9.1    | Adaptador DBT para PostgreSQL |

---

## âš¡ InicializaÃ§Ã£o do ambiente com Docker:

```bash
docker-compose build airflow
docker-compose up -d
```

---

## ğŸ—‚ï¸ Estrutura do Projeto:

```text
pdp-dw-powerbi/
â”œâ”€â”€ airflow/                 # OrquestraÃ§Ã£o de pipelines ETL/ELT com Airflow
â”‚   â”œâ”€â”€ dags/                # DefiniÃ§Ã£o dos DAGs
â”‚   â”œâ”€â”€ logs/                # Armazenamento de logs de execuÃ§Ã£o dos DAGs
â”‚   â””â”€â”€ plugins/             # Plugins customizados do Airflow
â”œâ”€â”€ config/                  # Arquivos de configuraÃ§Ã£o do projeto
â”œâ”€â”€ data/                    # Dados brutos e processados
â”‚   â”œâ”€â”€ extracted/           # Dados extraÃ­dos das fontes
â”‚   â””â”€â”€ processed/           # Dados transformados e preparados para load
â”œâ”€â”€ dbt/                     # Projeto DBT
â”‚   â”œâ”€â”€ models/              
â”‚   â”‚   â”œâ”€â”€ 01_staging/      # Modelos staging (limpeza e padronizaÃ§Ã£o de dados)
â”‚   â”‚   â”œâ”€â”€ 02_core/         # Modelos core (dados integrados e limpos)
â”‚   â”‚   â””â”€â”€ 03_marts/        # Modelos marts (tabelas para anÃ¡lise e dashboards)
â”‚   â”œâ”€â”€ seeds/               # Seeds (ex.: dim_date, dim_time)
â”‚   â”œâ”€â”€ snapshots/           # Snapshots de tabelas para histÃ³rico de mudanÃ§as
â”‚   â”œâ”€â”€ tests/               # Testes de qualidade do DBT
â”‚   â”œâ”€â”€ dbt_project.yml      # ConfiguraÃ§Ã£o do projeto DBT
â”‚   â””â”€â”€ profiles.yml         # ConfiguraÃ§Ã£o de conexÃ£o com o banco
â”œâ”€â”€ docs/                    # DocumentaÃ§Ã£o do projeto
â”‚   â”œâ”€â”€ diagrams/            # Diagramas de bancos OLTP e DWH
â”‚   â”œâ”€â”€ powerbi_screenshots/ # Capturas de tela de dashboards
â”‚   â””â”€â”€ data_dictionary.md   # DicionÃ¡rio de dados
â”œâ”€â”€ reports/                 # RelatÃ³rios Power BI exportados
â”œâ”€â”€ scripts/                 # Pipelines ETL e scripts auxiliares (ex.: geraÃ§Ã£o de seeds via Python)
â”œâ”€â”€ .env                     # VariÃ¡veis de ambiente do projeto
â”œâ”€â”€ docker-compose.yml       # ConfiguraÃ§Ã£o para execuÃ§Ã£o de containers Docker
â”œâ”€â”€ Dockerfile               # DefiniÃ§Ãµes da imagem Docker do projeto
â”œâ”€â”€ main.py                  # Script para execuÃ§Ã£o local
â”œâ”€â”€ README.md                # DocumentaÃ§Ã£o do projeto
â””â”€â”€ requirements.txt         # DependÃªncias Python
```

---

## ğŸ§© Diagrama do Modelo OLTP:
![Diagrama OLTP](docs/diagrams/oltp_model.png)

## ğŸ§  Diagrama do Modelo OLAP:
![Diagrama OLAP](docs/diagrams/olap_model.png)